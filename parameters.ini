[META TOKENS]
start = <S>
end = </S>
unknown = <UNK>
padding = <PAD>

[SAMPLES]
train_source = train.en
train_target = train.bg
validation_source = dev.en
validation_target = dev.bg
test_source = test.en
test_target = test.bg
threshold = 3

[SERIALISATION]
train_samples = train.pcl
validation_samples = validation.pcl
test_samples = test.pcl
dictionaries = dictionaries.pcl
model = nmt_model.pcl
optimizer = optimizer.optim

[ENCODER]
embedding_size = 128
hidden_size = 256
is_bidirectional = True
num_layers = 1
rnn_dropout = 0.0

[DECODER]
embedding_size = 128
hidden_size = 256
num_layers = 2
rnn_dropout = 0.0

[ATTENTION]
size = 256
is_multiplicative = True

[MODEL]
do_initial_binding = True
preprojection_nonlinearity = None

[TRAIN PARAMS]
uniform_init = 0.1
learning_rate = 0.001
learning_rate_decay = 0.5
max_gradient_norm = 5.0
batch_size = 32
max_epochs = 2
log_interval = 10
test_interval = 2000
max_patience = 5
max_trials = 5
